{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pyemd import emd\n",
    "import valores\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCIONES ##\n",
    "\n",
    "\n",
    "class TFM:\n",
    "\n",
    "    def __init__(self,path):\n",
    "        self.X_tr = scipy.sparse.load_npz(path+'X_tr.npz')\n",
    "        self.X_tst = scipy.sparse.load_npz(path+'X_tst.npz')\n",
    "        self.y_tr = np.load(path+'y_tr.npy')\n",
    "        self.y_tst = np.load(path+'y_tst.npy')\n",
    "        # Se binarizan las caracteristicas \n",
    "        self.y_tr=MultiLabelBinarizer().fit_transform(self.y_tr)\n",
    "        self.y_tst=MultiLabelBinarizer().fit_transform(self.y_tst)\n",
    "        # Escalado \n",
    "        scaler = MaxAbsScaler().fit(self.X_tr)\n",
    "        self.X_tr=scaler.transform(self.X_tr)\n",
    "        self.X_tst=scaler.transform(self.X_tst)\n",
    "        self.X_tr_simpli= None\n",
    "        self.simplificador = False\n",
    "        self.modelo = None\n",
    "        self.clf= None\n",
    "        self.columns= None\n",
    "        print ('Dataset cargado y preprocesado')\n",
    "\n",
    "    def reduce_features(self,num_data):\n",
    "        columns=np.array([])\n",
    "        for i in range(np.shape(self.X_tr)[1]):\n",
    "            if self.X_tr[:,i].count_nonzero()> num_data:\n",
    "                columns=np.append(columns,i)\n",
    "        np.savetxt('features'+num_data+'.txt',columns,delimiter=',')\n",
    "        print('Las características han sido reducidas')\n",
    "\n",
    "    def simplify_dataset(self,features,tr_size):\n",
    "        self.X_tr_simpli=self.X_tr\n",
    "        self.y_tr_simpli=self.y_tr\n",
    "        \n",
    "        self.columns=np.loadtxt('features'+features+'.txt',delimiter=',')\n",
    "        self.X_tr_simpli=self.X_tr[:,self.columns]\n",
    "        \"\"\"\n",
    "        self.svd = TruncatedSVD(n_components=int(features), n_iter=5, random_state=42)\n",
    "        \n",
    "        self.X_tr_simpli=self.svd.fit_transform(self.X_tr)\n",
    "        \"\"\"\n",
    "        self.X_tr_simpli, __, self.y_tr_simpli, __ = train_test_split(self.X_tr_simpli, self.y_tr_simpli, test_size=(1-tr_size), random_state=42)\n",
    "        print('Simplificación finalizada')\n",
    "        print(np.shape(self.X_tr_simpli))\n",
    "\n",
    "    def use_simplify(self,boolean):\n",
    "        self.simplificador= boolean\n",
    "        \n",
    "    def grid_search_cv(self,classifier,parameters,metodo):\n",
    "        if (metodo == 0):\n",
    "            classif = OneVsRestClassifier(classifier)\n",
    "        elif (metodo==1):\n",
    "            classif = ClassifierChain(classifier)\n",
    "        model_tunning = GridSearchCV(classif, param_grid=parameters,cv=4,verbose=50, n_jobs=-1,scoring='accuracy')\n",
    "        if (self.simplificador):\n",
    "            model_tunning.fit(self.X_tr_simpli, self.y_tr_simpli)\n",
    "        else :\n",
    "            model_tunning.fit(self.X_tr, self.y_tr)\n",
    "        print (model_tunning.best_score_)\n",
    "        print (model_tunning.best_params_)\n",
    "        self.modelo = model_tunning.best_estimator_\n",
    "\n",
    "    def fitting_classifier(self):\n",
    "        if (self.simplificador):\n",
    "            self.clf=self.modelo.fit(self.X_tr,self.y_tr)\n",
    "        else :\n",
    "            self.clf=self.modelo\n",
    "\n",
    "    def metrics(self):\n",
    "        if (self.simplificador):\n",
    "            self.y_pred=self.clf.predict(self.X_tst)\n",
    "        else :\n",
    "            self.y_pred=self.clf.predict(self.X_tst)\n",
    "        accuracy=mtc.accuracy_score(self.y_tst,self.y_pred)\n",
    "        hamming=mtc.hamming_loss(self.y_tst,self.y_pred)\n",
    "        precision=mtc.precision_score(self.y_tst,self.y_pred,average='micro')\n",
    "        print(\"Total accuracy: \", accuracy)\n",
    "        print(\"Hamming loss: \", hamming)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(mtc.classification_report(self.y_tst,self.y_pred))\n",
    "        #print(\"Accuracy per class:\")\n",
    "        aux=0\n",
    "        for i in range(np.shape(self.y_pred)[1]):\n",
    "            #print (\"Class \" ,i,\": \" ,mtc.accuracy_score(self.y_tst[:,i],y_pred[:,i]))\n",
    "            aux=aux+mtc.accuracy_score(self.y_tst[:,i],self.y_pred[:,i])\n",
    "        print(\"Accuracy media: \",aux/37)\n",
    "        distance_matrix=np.ones((37,37))*(1/37)\n",
    "        np.fill_diagonal(distance_matrix,0)\n",
    "        emd_aux=0\n",
    "        for i in range (np.shape(self.y_tst)[0]):\n",
    "            emd_aux= emd_aux + emd(self.y_tst[i,:].astype(float),self.y_pred[i,:].astype(float),distance_matrix)\n",
    "        \n",
    "        print(\"EMD: \", emd_aux/(np.shape(self.y_tst)[0]))\n",
    "        print(\"METRICAS DE LABEL RANKING: \")\n",
    "        spearman=scipy.stats.spearmanr(self.y_tst, self.y_pred)[0]\n",
    "        print(\"Spearmans Rank Correlation Coefficient: \" + spearman)\n",
    "        kendall=scipy.stats.kendalltau(self.y_tst, self.y_pred)[0]\n",
    "        print(\"Kendall’s tau Correlation Coefficient: \" + kendall)\n",
    "        \n",
    "        \n",
    "\n",
    "class TFM_RBM:\n",
    "\n",
    "    def __init__(self,path):\n",
    "        self.X_tr = scipy.sparse.load_npz(path+'X_tr.npz')\n",
    "        self.X_tst = scipy.sparse.load_npz(path+'X_tst.npz')\n",
    "        self.y_tr = np.load(path+'y_tr.npy')\n",
    "        self.y_tst = np.load(path+'y_tst.npy')\n",
    "        # Se binarizan las caracteristicas \n",
    "        self.y_tr=MultiLabelBinarizer().fit_transform(self.y_tr)\n",
    "        self.y_tst=MultiLabelBinarizer().fit_transform(self.y_tst)\n",
    "        # Escalado \n",
    "        scaler = MaxAbsScaler().fit(self.X_tr)\n",
    "        self.X_tr=scaler.transform(self.X_tr)\n",
    "        self.X_tst=scaler.transform(self.X_tst)\n",
    "        self.modelo = None\n",
    "        self.clf= None\n",
    "        self.columns= None\n",
    "        print ('Dataset cargado y preprocesado')\n",
    "\n",
    "    def rbm_extraction(self):\n",
    "        rbm=BernoulliRBM(random_state=0, verbose=True,learning_rate=0.06,n_iter=20,n_components=200)\n",
    "        rbm.fit(self.X_tr)\n",
    "        filename = 'rbm_data_200.sav'\n",
    "        pickle.dump(rbm, open(filename, 'wb'))\n",
    "        print('Modelo RBM guardado')\n",
    "\n",
    "\n",
    "        \n",
    "    def rbm_gridsearch(self,classifier,metodo,filename):\n",
    "        self.rbm_data = pickle.load(open(filename, 'rb'))\n",
    "        self.X_tr=self.rbm_data.transform(self.X_tr)\n",
    "        print (\"Transformación finalizada\")\n",
    "        if (metodo == 0):\n",
    "            classif = OneVsRestClassifier(classifier)\n",
    "        elif (metodo==1):\n",
    "            classif = ClassifierChain(classifier)\n",
    "        model_tunning = GridSearchCV(classif, param_grid=parameters,cv=4,verbose=50, n_jobs=-1,scoring='accuracy')\n",
    "        model_tunning.fit(self.X_tr, self.y_tr)\n",
    "        print (model_tunning.best_score_)\n",
    "        print (model_tunning.best_params_)\n",
    "        self.modelo = model_tunning.best_estimator_\n",
    "\n",
    "    def fitting_classifier(self):\n",
    "        self.clf=self.modelo\n",
    "\n",
    "    def metrics(self):\n",
    "        self.y_pred=self.clf.predict(self.rbm_data.transform(self.X_tst))\n",
    "        accuracy=mtc.accuracy_score(self.y_tst,self.y_pred)\n",
    "        hamming=mtc.hamming_loss(self.y_tst,self.y_pred)\n",
    "        precision=mtc.precision_score(self.y_tst,self.y_pred,average='micro')\n",
    "        print(\"Total accuracy: \", accuracy)\n",
    "        print(\"Hamming loss: \", hamming)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(mtc.classification_report(self.y_tst,self.y_pred))\n",
    "        #print(\"Accuracy per class:\")\n",
    "        aux=0\n",
    "        for i in range(np.shape(self.y_pred)[1]):\n",
    "            #print (\"Class \" ,i,\": \" ,mtc.accuracy_score(self.y_tst[:,i],y_pred[:,i]))\n",
    "            aux=aux+mtc.accuracy_score(self.y_tst[:,i],self.y_pred[:,i])\n",
    "        print(\"Accuracy media: \",aux/37)\n",
    "        distance_matrix=np.ones((37,37))*(1/37)\n",
    "        np.fill_diagonal(distance_matrix,0)\n",
    "        emd_aux=0\n",
    "        for i in range (np.shape(self.y_tst)[0]):\n",
    "            emd_aux= emd_aux + emd(self.y_tst[i,:].astype(float),self.y_pred[i,:].astype(float),distance_matrix)\n",
    "        \n",
    "        print(\"EMD: \", emd_aux/(np.shape(self.y_tst)[0]))\n",
    "        print(\"METRICAS DE LABEL RANKING: \")\n",
    "        spearman=scipy.stats.spearmanr(self.y_tst, self.y_pred)[0]\n",
    "        print(\"Spearmans Rank Correlation Coefficient: \" + spearman)\n",
    "        kendall=scipy.stats.kendalltau(self.y_tst, self.y_pred)[0]\n",
    "        print(\"Kendall’s tau Correlation Coefficient: \" + kendall)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_string=input('Introduce el directorio del dataset')\n",
    "clasificacion=TFM(path_string)\n",
    "print('Inicio del programa clasificador')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ask2=int(input('Que clasificador vas a usar?: '))\n",
    "    clasificador=valores.clasificadores_dict[ask2]\n",
    "    metod=int(input('Que metodo vas a usar?: Introduce 0 para One vs Rest, o 1 para Classifier Chain'))\n",
    "        \n",
    "    while True:\n",
    "        ask1=input(('Quieres usar simplificacion para entrenar el algoritmo?'))\n",
    "        if (ask1.lower()=='si'):\n",
    "            non_zero_data=input(('Introduce el numero de elementos no nulos por categoria que consideras aceptable'))\n",
    "            training_size=float(input('Introduce el porcentaje de tamano de datos de entrenamiento que quieres usar para simplificar'))\n",
    "            print('Realizando simplificacion del dataset...')\n",
    "            clasificacion.simplify_dataset(non_zero_data,training_size)\n",
    "            clasificacion.use_simplify(True)\n",
    "        elif (ask1.lower()=='no'):\n",
    "            clasificacion.use_simplify(False)\n",
    "        print(\"Iniciando tunning de los parámetros:\")\n",
    "        clasificacion.grid_search_cv(clasificador,valores.parametros_dict[(clasificador,metod)],metod)    \n",
    "        print(\"Tunning finalizado:\")  \n",
    "        ask5=input('Quieres continuar con el entrenamiento?')\n",
    "        if (ask5.tolower()=='no'){\n",
    "            break\n",
    "        }\n",
    "        print(\"Entrenando el algoritmo con los mejores parametros...\")\n",
    "        clasificacion.fitting_classifier()\n",
    "        print(\"Entrenamiento finalizado, se procede a predecir las etiquetas\")\n",
    "        print(\"Mostrando metricas obtenidas\")\n",
    "        clasificacion.metrics()\n",
    "        ask3=input('Quieres probar a variar la simplificacion?')\n",
    "        if (ask3.lower()=='si'):\n",
    "            continue\n",
    "        elif (ask3.lower()=='no'):\n",
    "            break\n",
    "            \n",
    "    ask4=input('Quieres probar con otro clasificador o finalizamos el programa?')\n",
    "    if (ask4.lower()=='si'):\n",
    "        continue\n",
    "    elif (ask4.lower()=='no'):\n",
    "        break\n",
    "\n",
    "print(\"Fin del programa clasificador\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_string=input('Introduce el directorio del dataset')\n",
    "clasificacion=TFM_RBM(path_string)\n",
    "print('Inicio del programa clasificador')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ask2=int(input('Que clasificador vas a usar?: '))\n",
    "    clasificador=valores.clasificadores_dict[ask2]\n",
    "    metod=int(input('Que metodo vas a usar?: Introduce 0 para One vs Rest, o 1 para Classifier Chain'))\n",
    "        \n",
    "    while True:\n",
    "        print(\"Iniciando tunning de los parámetros:\")\n",
    "        clasificacion.pipeline_rbm(clasificador,metod)    \n",
    "        print(\"Tunning finalizado:\")  \n",
    "        ask5=input('Quieres continuar con el entrenamiento?')\n",
    "        print(\"Entrenando el algoritmo con los mejores parametros...\")\n",
    "        clasificacion.fitting_classifier()\n",
    "        print(\"Entrenamiento finalizado, se procede a predecir las etiquetas\")\n",
    "        print(\"Mostrando metricas obtenidas\")\n",
    "        clasificacion.metrics()\n",
    "        break;\n",
    "            \n",
    "    ask4=input('Quieres probar con otro clasificador o finalizamos el programa?')\n",
    "    if (ask4.lower()=='si'):\n",
    "        continue\n",
    "    elif (ask4.lower()=='no'):\n",
    "        break\n",
    "\n",
    "print(\"Fin del programa clasificador\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_string=\"../../Datasets/dataset/\"\n",
    "metod=0\n",
    "clasificador=valores.LogisticRegression()\n",
    "parameters={\n",
    "    \"estimator__C\": [1],\n",
    "    \"estimator__solver\": [\"liblinear\"],\n",
    "    \"estimator__tol\": [0.01]\n",
    "}\n",
    "clasificacion=TFM(path_string)\n",
    "clasificacion.use_simplify(False)\n",
    "clasificacion.grid_search_cv(clasificador,parameters,metod)\n",
    "clasificacion.fitting_classifier()\n",
    "clasificacion.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado y preprocesado\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.43, time = 1411.94s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.95, time = 1380.50s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.73, time = 1384.05s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -32.49, time = 1380.87s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -31.79, time = 1380.62s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -33.60, time = 1380.58s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -31.99, time = 1382.60s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -32.43, time = 1383.53s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -33.59, time = 1380.42s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -31.74, time = 1381.17s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.76, time = 1380.38s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -32.45, time = 1381.22s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -32.08, time = 1384.51s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -32.50, time = 1488.13s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -32.86, time = 1400.37s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -31.74, time = 1383.92s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.35, time = 1382.74s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -32.40, time = 1386.15s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -32.16, time = 1383.47s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -32.95, time = 1383.12s\n",
      "Modelo RBM guardado\n"
     ]
    }
   ],
   "source": [
    "path_string=\"../../Datasets/dataset/\"\n",
    "clasificacion=TFM_RBM(path_string)\n",
    "clasificacion.rbm_extraction()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
