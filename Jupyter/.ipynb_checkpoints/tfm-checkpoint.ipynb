{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS ##\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCIONES ##\n",
    "\n",
    "class TFM:\n",
    "\n",
    "    def __init__(self,path):\n",
    "        self.X_tr = scipy.sparse.load_npz(path+'X_tr.npz')\n",
    "        self.X_tst = scipy.sparse.load_npz(path+'X_tst.npz')\n",
    "        self.y_tr = np.load(path+'y_tr.npy')\n",
    "        self.y_tst = np.load(path+'y_tst.npy')\n",
    "        # Se binarizan las caracteristicas \n",
    "        self.y_tr=MultiLabelBinarizer().fit_transform(self.y_tr)\n",
    "        self.y_tst=MultiLabelBinarizer().fit_transform(self.y_tst)\n",
    "        # Escalado \n",
    "        scaler = MaxAbsScaler().fit(self.X_tr)\n",
    "        self.X_tr=scaler.transform(self.X_tr)\n",
    "        self.X_tst=scaler.transform(self.X_tst)\n",
    "        self.X_tr_simpli= None\n",
    "        self.simplificador = False\n",
    "        self.modelo = None\n",
    "        self.clf= None\n",
    "        print ('Dataset cargado y preprocesado')\n",
    "\n",
    "    def reduce_features(self,num_data):\n",
    "        columns=np.array([])\n",
    "        for i in range(np.shape(self.X_tr)[1]):\n",
    "            if self.X_tr[:,i].count_nonzero()> num_data:\n",
    "                columns=np.append(columns,i)\n",
    "        np.savetxt('features'+num_data+'.txt',columns,delimiter=',')\n",
    "        print('Las características han sido reducidas')\n",
    "\n",
    "    def simplify_dataset(self,features,tr_size):\n",
    "        self.X_tr_simpli=self.X_tr\n",
    "        self.y_tr_simpli=self.y_tr\n",
    "        columns=np.loadtxt('features'+features+'.txt',delimiter=',')\n",
    "        self.X_tr_simpli=self.X_tr[:,columns]\n",
    "        self.X_tr_simpli, __, self.y_tr_simpli, __ = train_test_split(self.X_tr_simpli, self.y_tr_simpli, test_size=(1-tr_size), random_state=42)\n",
    "        print('Simplificación finalizada')\n",
    "\n",
    "    def use_simplify(self,boolean):\n",
    "        self.simplificador= boolean\n",
    "        \n",
    "    def grid_search_cv(self,classifier,parameters,metodo):\n",
    "        if (metodo == 0):\n",
    "            classif = OneVsRestClassifier(classifier)\n",
    "        elif (metodo==1):\n",
    "            classif = ClassifierChain(classifier)\n",
    "        model_tunning = GridSearchCV(classif, param_grid=parameters,cv=4)\n",
    "        if (self.simplificador):\n",
    "            model_tunning.fit(self.X_tr_simpli, self.y_tr_simpli)\n",
    "        else :\n",
    "            model_tunning.fit(self.X_tr, self.y_tr)\n",
    "        print (model_tunning.best_score_)\n",
    "        print (model_tunning.best_params_)\n",
    "        self.modelo = model_tunning.best_estimator_\n",
    "\n",
    "    def fitting_classifier(self):\n",
    "        self.clf=self.modelo\n",
    "        self.clf.fit(self.X_tr,self.y_tr)\n",
    "    \n",
    "    def metrics(self):\n",
    "        y_pred=self.clf.predict(self.X_tst)\n",
    "        accuracy=mtc.accuracy_score(self.y_tst,y_pred)\n",
    "        hamming=mtc.hamming_loss(self.y_tst,y_pred)\n",
    "        precision=mtc.precision_score(self.y_tst,y_pred,average='micro')\n",
    "        print(\"Total accuracy: \", accuracy)\n",
    "        print(\"Hamming loss: \", hamming)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(mtc.classification_report(self.y_tst,y_pred))\n",
    "        print(\"Accuracy per class:\")\n",
    "        aux=0\n",
    "        for i in range(np.shape(y_pred)[1]):\n",
    "            print (\"Class \" ,i,\": \" ,mtc.accuracy_score(self.y_tst[:,i],y_pred[:,i]))\n",
    "            aux=aux+mtc.accuracy_score(self.y_tst[:,i],y_pred[:,i])\n",
    "        print(\"Accuracy media: \",aux/37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado y preprocesado\n"
     ]
    }
   ],
   "source": [
    "#Variables a usar \n",
    "path_string='../../Datasets/dataset/'\n",
    "non_zero_data='250'\n",
    "training_size=0.1\n",
    "clasificador=LogisticRegression()\n",
    "metod=0\n",
    "#mlp=MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(300,200,100,50), random_state=0)\n",
    "parameters0 = {\n",
    "    \"estimator__C\": [1],\n",
    "    \"estimator__solver\": [\"liblinear\"],\n",
    "    \"estimator__tol\": [0.01],\n",
    "    \"estimator__class_weight\":[None]\n",
    "}\n",
    "parameters1 = {\n",
    "    \"base_estimator__C\": [4],\n",
    "    \"base_estimator__solver\": [\"liblinear\"],\n",
    "    \"base_estimator__tol\": [0.01],\n",
    "    \"base_estimator__max_iter\":[10000]\n",
    "}\n",
    "\n",
    "\n",
    "clasificacion= TFM(path_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplificación finalizada\n"
     ]
    }
   ],
   "source": [
    "#clasificacion.reduce_features(10000)\n",
    "clasificacion.simplify_dataset('500',training_size)\n",
    "clasificacion.use_simplify(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597402597402597\n",
      "{'estimator__class_weight': None, 'estimator__C': 1, 'estimator__solver': 'liblinear', 'estimator__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "clasificacion.grid_search_cv(clasificador,parameters0,metod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificacion.fitting_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total accuracy: ', 0.39135317237507017)\n",
      "('Hamming loss: ', 0.02901497792008741)\n",
      "('Precision: ', 0.7681099084096586)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77       109\n",
      "           1       0.78      0.46      0.58       138\n",
      "           2       0.77      0.64      0.70       224\n",
      "           3       0.76      0.55      0.64       180\n",
      "           4       0.82      0.69      0.75       177\n",
      "           5       0.75      0.63      0.69       262\n",
      "           6       0.65      0.47      0.55        55\n",
      "           7       0.79      0.67      0.73       341\n",
      "           8       0.64      0.52      0.57        91\n",
      "           9       0.60      0.38      0.47        65\n",
      "          10       0.72      0.66      0.69       181\n",
      "          11       0.57      0.16      0.25        25\n",
      "          12       0.69      0.51      0.58       172\n",
      "          13       0.67      0.20      0.31        10\n",
      "          14       0.91      0.68      0.78       173\n",
      "          15       0.65      0.38      0.48       146\n",
      "          16       0.69      0.58      0.63       113\n",
      "          17       0.47      0.19      0.27        42\n",
      "          18       0.56      0.24      0.34        41\n",
      "          19       0.54      0.28      0.37        25\n",
      "          20       0.00      0.00      0.00        21\n",
      "          21       0.82      0.69      0.75       155\n",
      "          22       0.95      0.69      0.80        26\n",
      "          23       0.75      0.47      0.58        19\n",
      "          24       0.50      0.18      0.26        17\n",
      "          25       0.78      0.70      0.74        30\n",
      "          26       0.90      0.71      0.79        78\n",
      "          27       0.94      0.79      0.86        38\n",
      "          28       0.79      0.22      0.34        51\n",
      "          29       1.00      0.62      0.77        32\n",
      "          30       0.57      0.27      0.36        15\n",
      "          31       0.67      0.24      0.35        17\n",
      "          32       0.89      0.50      0.64        16\n",
      "          33       0.84      0.72      0.78        36\n",
      "          34       0.91      0.87      0.89        45\n",
      "          35       0.50      0.43      0.46        14\n",
      "          36       0.83      0.50      0.62        20\n",
      "\n",
      "   micro avg       0.77      0.58      0.66      3200\n",
      "   macro avg       0.72      0.49      0.57      3200\n",
      "weighted avg       0.76      0.58      0.65      3200\n",
      " samples avg       0.72      0.65      0.65      3200\n",
      "\n",
      "Accuracy per class:\n",
      "('Class ', 0, ': ', 0.9747332959011791)\n",
      "('Class ', 1, ': ', 0.9483436271757439)\n",
      "('Class ', 2, ': ', 0.9309376754632229)\n",
      "('Class ', 3, ': ', 0.9371139809096013)\n",
      "('Class ', 4, ': ', 0.9539584503088153)\n",
      "('Class ', 5, ': ', 0.9152161706906232)\n",
      "('Class ', 6, ': ', 0.9758562605277934)\n",
      "('Class ', 7, ': ', 0.9034250421111735)\n",
      "('Class ', 8, ': ', 0.9601347557551937)\n",
      "('Class ', 9, ': ', 0.9679955081414935)\n",
      "('Class ', 10, ': ', 0.9393599101628298)\n",
      "('Class ', 11, ': ', 0.9865244244806288)\n",
      "('Class ', 12, ': ', 0.9298147108366086)\n",
      "('Class ', 13, ': ', 0.9949466591802358)\n",
      "('Class ', 14, ': ', 0.9623806850084222)\n",
      "('Class ', 15, ': ', 0.9326221224031443)\n",
      "('Class ', 16, ': ', 0.9573273441886581)\n",
      "('Class ', 17, ': ', 0.9758562605277934)\n",
      "('Class ', 18, ': ', 0.9781021897810219)\n",
      "('Class ', 19, ': ', 0.9865244244806288)\n",
      "('Class ', 20, ': ', 0.9882088714205502)\n",
      "('Class ', 21, ': ', 0.9601347557551937)\n",
      "('Class ', 22, ': ', 0.9949466591802358)\n",
      "('Class ', 23, ': ', 0.9927007299270073)\n",
      "('Class ', 24, ': ', 0.9904548006737788)\n",
      "('Class ', 25, ': ', 0.991577765300393)\n",
      "('Class ', 26, ': ', 0.9837170129140932)\n",
      "('Class ', 27, ': ', 0.9943851768669287)\n",
      "('Class ', 28, ': ', 0.9758562605277934)\n",
      "('Class ', 29, ': ', 0.9932622122403144)\n",
      "('Class ', 30, ': ', 0.9921392476137002)\n",
      "('Class ', 31, ': ', 0.991577765300393)\n",
      "('Class ', 32, ': ', 0.9949466591802358)\n",
      "('Class ', 33, ': ', 0.991577765300393)\n",
      "('Class ', 34, ': ', 0.9943851768669287)\n",
      "('Class ', 35, ': ', 0.9921392476137002)\n",
      "('Class ', 36, ': ', 0.9932622122403144)\n",
      "('Accuracy media: ', 0.9709850220799126)\n"
     ]
    }
   ],
   "source": [
    "clasificacion.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGUNDA SOLUCIÓN\n",
    "#tunning \n",
    "parameters = {\n",
    "    \"base_estimator__C\": [1,10,100,1000],\n",
    "    \"base_estimator__solver\": [\"liblinear\"],\n",
    "    \"base_estimator__tol\": [0.1,0.01,0.001,0.0001],\n",
    "    \"base_estimator__max_iter\":[10000]\n",
    "}\n",
    "\n",
    "modelo2=classifier_chain_tunning(X_aux,y_aux,LogisticRegression(),parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
