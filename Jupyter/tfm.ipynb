{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS ##\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = scipy.sparse.load_npz('../../Datasets/dataset/X_tr.npz')\n",
    "X_tst = scipy.sparse.load_npz('../../Datasets/dataset/X_tst.npz')\n",
    "y_tr = np.load('../../Datasets/dataset/y_tr.npy')\n",
    "y_tst = np.load('../../Datasets/dataset/y_tst.npy')\n",
    "# Se binarizan las caracteristicas \n",
    "y_tr=MultiLabelBinarizer().fit_transform(y_tr)\n",
    "y_tst=MultiLabelBinarizer().fit_transform(y_tst)\n",
    "# Escalado \n",
    "scaler = MaxAbsScaler().fit(X_tr)\n",
    "X_tr=scaler.transform(X_tr)\n",
    "X_tst=scaler.transform(X_tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-f94b37ffe12d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# REDUCCIÓN DE DIMENSIÓN PRIMERA TÉCNICA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_tst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mReduced\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0malways\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdense\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \"\"\"\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# REDUCCIÓN DE DIMENSIÓN PRIMERA TÉCNICA\n",
    "svd = TruncatedSVD(n_components=17, n_iter=10, random_state=42)\n",
    "X_tr = svd.fit_transform(X_tr)  \n",
    "X_tst = svd.transform(X_tst)  \n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDUCCION TAMAÑO TRAINING Y ELIMINAR CARACTERISTICAS INSERVIBLES\n",
    "\n",
    "columns=np.array([])\n",
    "for i in range(np.shape(X_tr)[1]):\n",
    "    if X_tr[:,i].count_nonzero()> 250:\n",
    "        columns=np.append(columns,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4295,)\n"
     ]
    }
   ],
   "source": [
    "#Se guardan las caracteristicas mas importantes para evitar repetir este proceso siempre\n",
    "np.savetxt('features250.txt',columns,delimiter=',')\n",
    "\n",
    "print(np.shape(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan las caracteristicas guardadas\n",
    "columns=np.loadtxt('features500.txt',delimiter=',')\n",
    "X_tr2=X_tr[:,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducir tamaño de muestra para un tunning mas rapido\n",
    "X_aux, __, y_aux, __ = train_test_split(X_tr2, y_tr, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_aux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4be57560b2ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel_tunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel_tunning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_aux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_aux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel_tunning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_aux' is not defined"
     ]
    }
   ],
   "source": [
    "## Clasificador de regresión logística\n",
    "classif = OneVsRestClassifier(LogisticRegression())\n",
    "parameters = {\n",
    "    \"estimator__C\": [10],\n",
    "    \"estimator__solver\": [\"liblinear\"],\n",
    "    \"estimator__tol\": [0.1]\n",
    "}\n",
    "\n",
    "model_tunning = GridSearchCV(classif, param_grid=parameters,cv=4)\n",
    "\n",
    "model_tunning.fit(X_aux, y_aux)\n",
    "\n",
    "print (model_tunning.best_score_)\n",
    "print (model_tunning.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37310668554215587\n",
      "{'estimator__C': 1, 'estimator__class_weight': None, 'estimator__solver': 'liblinear', 'estimator__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "classif = OneVsRestClassifier(LogisticRegression())\n",
    "parameters = {\n",
    "    \"estimator__C\": [1],\n",
    "    \"estimator__solver\": [\"liblinear\"],\n",
    "    \"estimator__tol\": [0.01],\n",
    "    \"estimator__class_weight\":[None]\n",
    "}\n",
    "\n",
    "model_tunning = GridSearchCV(classif, param_grid=parameters,cv=4)\n",
    "\n",
    "model_tunning.fit(X_tr, y_tr)\n",
    "\n",
    "print (model_tunning.best_score_)\n",
    "print (model_tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classif=OneVsRestClassifier(LogisticRegression(C=0.6,tol=0.1,solver='liblinear'))\n",
    "#classif.fit(X_tr,y_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35991016282987087\n",
      "0.03130643276628678\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_tunning.predict(X_tst)\n",
    "accuracy=mtc.accuracy_score(y_tst,y_pred)\n",
    "hamming=mtc.hamming_loss(y_tst,y_pred)\n",
    "print(accuracy)\n",
    "print(hamming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print (\"Accuracy:\" mtc.accuracy_score(y_tst[:,i],y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBM -- SE IMPLEMENTARÁ CON UN PIPELINE PERO AÚN FALTA ENTENDER MEJOR EL FUNCIONAMIENTO DE BERNOULLIRBM -- \n",
    "#-- NO EJECUTAR-- #\n",
    "logistic = OneVsRestClassifier(LogisticRegression())\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "rbm_features_classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "rbm.n_components = 100\n",
    "rbm_features_classifier.fit(X_tr, y_tr)\n",
    "Y_pred2 = rbm_features_classifier.predict(X_tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
